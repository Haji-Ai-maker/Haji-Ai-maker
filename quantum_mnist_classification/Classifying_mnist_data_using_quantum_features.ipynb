{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classifying mnist data using quantum features.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Haji-Ai-maker/Haji-Ai-maker/blob/main/quantum_mnist_classification/Classifying_mnist_data_using_quantum_features.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_DTuhWgsJoo"
      },
      "source": [
        "We will first install Qulacs plugin with GPU for Pennylane and then refresh the environment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5zajCphfSmQ",
        "outputId": "9b0fe901-7176-46cf-f1d4-a17bcbd718db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        }
      },
      "source": [
        "import os\n",
        "!pip install git+https://github.com/kareem1925/pennylane-qulacs@GPU_support\n",
        "os.kill(os.getpid(), 9)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/kareem1925/pennylane-qulacs@GPU_support\n",
            "  Cloning https://github.com/kareem1925/pennylane-qulacs (to revision GPU_support) to /tmp/pip-req-build-clb7771c\n",
            "  Running command git clone -q https://github.com/kareem1925/pennylane-qulacs /tmp/pip-req-build-clb7771c\n",
            "  Running command git checkout -b GPU_support --track origin/GPU_support\n",
            "  Switched to a new branch 'GPU_support'\n",
            "  Branch 'GPU_support' set up to track remote branch 'GPU_support' from 'origin'.\n",
            "Collecting pennylane>=0.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fa/2c/eada20029b81dbf9e1dce614f93b277449e2506284fef8450f038aadd5e1/PennyLane-0.8.0-py3-none-any.whl (195kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 9.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pennylane-qulacs==0.0.4) (1.17.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from pennylane-qulacs==0.0.4) (1.4.1)\n",
            "Collecting qulacs-gpu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/59/cb6505707bfc76a8d4a039dc779fc3de70a6b5428a4016423a5b072422f1/Qulacs-GPU-0.1.9.tar.gz (268kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 68.2MB/s \n",
            "\u001b[?25hCollecting toml\n",
            "  Downloading https://files.pythonhosted.org/packages/a2/12/ced7105d2de62fa7c8fb5fce92cc4ce66b57c95fb875e9318dba7f8c5db0/toml-0.10.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: autograd in /usr/local/lib/python3.6/dist-packages (from pennylane>=0.5.0->pennylane-qulacs==0.0.4) (1.3)\n",
            "Collecting appdirs\n",
            "  Downloading https://files.pythonhosted.org/packages/56/eb/810e700ed1349edde4cbdc1b2a21e28cdf115f9faf263f6bbf8447c1abf3/appdirs-1.4.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from pennylane>=0.5.0->pennylane-qulacs==0.0.4) (2.4)\n",
            "Collecting semantic-version==2.6\n",
            "  Downloading https://files.pythonhosted.org/packages/28/be/3a7241d731ba89063780279a5433f5971c1cf41735b64a9f874b7c3ff995/semantic_version-2.6.0-py3-none-any.whl\n",
            "Requirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.6/dist-packages (from autograd->pennylane>=0.5.0->pennylane-qulacs==0.0.4) (0.16.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->pennylane>=0.5.0->pennylane-qulacs==0.0.4) (4.4.1)\n",
            "Building wheels for collected packages: pennylane-qulacs, qulacs-gpu\n",
            "  Building wheel for pennylane-qulacs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pennylane-qulacs: filename=pennylane_qulacs-0.0.4-cp36-none-any.whl size=4565 sha256=a19761f9c721e874da6a48eeda931d642fd6cd4e972eb89396f11682c41c42cf\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-eb9omc4u/wheels/93/58/04/19f31c7d05f27562d0941ae63f8c34e73620017d13840d4d00\n",
            "  Building wheel for qulacs-gpu (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for qulacs-gpu: filename=Qulacs_GPU-0.1.9-cp36-cp36m-linux_x86_64.whl size=843504 sha256=ad478d3e31973ec60d0475e83bf33a1f2ce037bcabce4e3162bef676ceeb52b4\n",
            "  Stored in directory: /root/.cache/pip/wheels/cb/57/aa/800e4bdd8dfc7514f5c5a15e58e232f26f5ca481063dd2a4ef\n",
            "Successfully built pennylane-qulacs qulacs-gpu\n",
            "Installing collected packages: toml, appdirs, semantic-version, pennylane, qulacs-gpu, pennylane-qulacs\n",
            "  Found existing installation: semantic-version 2.8.4\n",
            "    Uninstalling semantic-version-2.8.4:\n",
            "      Successfully uninstalled semantic-version-2.8.4\n",
            "Successfully installed appdirs-1.4.3 pennylane-0.8.0 pennylane-qulacs-0.0.4 qulacs-gpu-0.1.9 semantic-version-2.6.0 toml-0.10.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hi-CUinnsk1U"
      },
      "source": [
        "Run the following command to make sure everything is working perfectly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZfhsYF95hgZv",
        "outputId": "4cb37f7c-05a6-415f-e698-2701f762d84a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import qulacs\n",
        "qulacs.QuantumStateGpu"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "qulacs.QuantumStateGpu"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJqHjVDQsrb_"
      },
      "source": [
        "from pennylane import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder,OneHotEncoder,normalize,LabelBinarizer\n",
        "from sklearn.utils import compute_sample_weight\n",
        "import pennylane as qml\n",
        "from sklearn.datasets import load_digits\n",
        "import warnings\n",
        "from sklearn.metrics import balanced_accuracy_score as acc\n",
        "from pennylane.optimize import AdamOptimizer,AdagradOptimizer\n",
        "\n",
        "np.seterr(all=\"ignore\")\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Fw67B-ttf7w"
      },
      "source": [
        "**Defining the log loss function along with softmax and accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNpZ1AbZxuJU"
      },
      "source": [
        "\n",
        "# this function is taken from scikit-learn code of meterics and it has been\n",
        "# modified to comply to autograd's numpy\n",
        "\n",
        "def log_loss(y_true, y_pred, eps=1e-15, normalize=True, sample_weight=None,\n",
        "             labels=None):\n",
        "\n",
        "\n",
        "    lb = LabelBinarizer()\n",
        "\n",
        "    if labels is not None:\n",
        "        lb.fit(labels)\n",
        "    else:\n",
        "        lb.fit(y_true)\n",
        "\n",
        "    if len(lb.classes_) == 1:\n",
        "        if labels is None:\n",
        "            raise ValueError('y_true contains only one label ({0}). Please '\n",
        "                             'provide the true labels explicitly through the '\n",
        "                             'labels argument.'.format(lb.classes_[0]))\n",
        "        else:\n",
        "            raise ValueError('The labels array needs to contain at least two '\n",
        "                             'labels for log_loss, '\n",
        "                             'got {0}.'.format(lb.classes_))\n",
        "\n",
        "    transformed_labels = lb.transform(y_true)\n",
        "\n",
        "    if transformed_labels.shape[1] == 1:\n",
        "        transformed_labels = np.append(1 - transformed_labels,\n",
        "                                       transformed_labels, axis=1)\n",
        "\n",
        "    # Clipping\n",
        "    y_pred = np.clip(y_pred, eps, 1 - eps)\n",
        "\n",
        "    # If y_pred is of single dimension, assume y_true to be binary\n",
        "    # and then check.\n",
        "    if y_pred.ndim == 1:\n",
        "        y_pred = y_pred[:, np.newaxis]\n",
        "    if y_pred.shape[1] == 1:\n",
        "        y_pred = np.append(1 - y_pred, y_pred, axis=1)\n",
        "\n",
        "    # Check if dimensions are consistent.\n",
        "#    transformed_labels = check_array(transformed_labels)\n",
        "    if len(lb.classes_) != y_pred.shape[1]:\n",
        "        if labels is None:\n",
        "            raise ValueError(\"y_true and y_pred contain different number of \"\n",
        "                             \"classes {0}, {1}. Please provide the true \"\n",
        "                             \"labels explicitly through the labels argument. \"\n",
        "                             \"Classes found in \"\n",
        "                             \"y_true: {2}\".format(transformed_labels.shape[1],\n",
        "                                                  y_pred.shape[1],\n",
        "                                                  lb.classes_))\n",
        "        else:\n",
        "            raise ValueError('The number of classes in labels is different '\n",
        "                             'from that in y_pred. Classes found in '\n",
        "                             'labels: {0}'.format(lb.classes_))\n",
        "\n",
        "    # Renormalize\n",
        "    y_pred /= y_pred.sum(axis=1)[:, np.newaxis]\n",
        "    loss = -(transformed_labels * np.log(y_pred)).sum(axis=1)\n",
        "#    print(loss)\n",
        "\n",
        "    return loss\n",
        "\n",
        "\n",
        "def accuracy_score(y_true, y_pred):\n",
        "    \"\"\"\n",
        "\n",
        "    This function computed the weighted aaverage accuarcy\n",
        "\n",
        "    \"\"\"\n",
        "    weights = compute_sample_weight('balanced',y_true)\n",
        "\n",
        "    return acc(y_true,y_pred,sample_weight=weights)\n",
        "\n",
        "def softmax(x):\n",
        "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
        "\n",
        "    e_x = np.exp(x - np.max(x))\n",
        "    return e_x / e_x.sum(axis=0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3oBtJeJtaKu"
      },
      "source": [
        "**Data loading and splitting**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUXWybtEh_5c",
        "outputId": "5f9c2885-356b-4cdf-d5d7-bd2144c0a0a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "X,y = load_digits(n_class=3,return_X_y=True)\n",
        "\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.1,random_state=5,stratify=y)\n",
        "\n",
        "la  = OneHotEncoder(sparse=False).fit(y.reshape(-1,1))\n",
        "\n",
        "y_train = la.transform(y_train.reshape(-1,1))\n",
        "\n",
        "y_test = la.transform(y_test.reshape(-1,1))\n",
        "\n",
        "y_test[:2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 1.],\n",
              "       [1., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLTGoD8st3kb"
      },
      "source": [
        "**Defining the quantum circuit**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQB5JG2nwWv5"
      },
      "source": [
        "# initialize the device\n",
        "dev = qml.device(\"qulacs.simulator\", wires=7,shots=1000,analytic = True)\n",
        "\n",
        "@qml.qnode(dev)\n",
        "def qclassifier(weights, X=None):\n",
        "\n",
        "\n",
        "    # pennylane normalizes the input for us by setting normalize to True so no need for any preprocessing\n",
        "    qml.templates.AmplitudeEmbedding(X,wires=list(range(7)),pad=0.0,normalize=True)\n",
        "\n",
        "### the following comments mimics the same line below except for CRX gate where you should define its weights\n",
        "### because the init template in pennylane doesn't do that it only initializes the rotation parameters\n",
        "\n",
        "#    for i in range(weights.shape[0]):\n",
        " #     for j in range(weights.shape[1]):\n",
        "  #      qml.Rot(*weights[i][j],wires=j)\n",
        "   #   for x in range(cnots.shape[1]):\n",
        "    #    qml.CRX(*cnots[i][x],wires=[x,(x+1)%6])\n",
        "\n",
        "\n",
        "    qml.templates.StronglyEntanglingLayers(weights,wires=list(range(7)))\n",
        "\n",
        "    return [qml.expval(qml.PauliZ(i)) for i in range(7)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_iLfovfugSB"
      },
      "source": [
        "### **The Cost Function**\n",
        "This fucntion contains the main logic of the full network. it takes a batched input with the weights and first pass the the quantum weights into the quantum classifier.\n",
        "Then it adds the bias to the output from Qcircuit. After that, we apply the classical operations the relu and softmax as shown in the for loop below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qj-Ofcr1wbzn"
      },
      "source": [
        "\n",
        "\n",
        "def cost(params, x, y):\n",
        "\n",
        "\n",
        "    # Compute prediction for each input in data batch\n",
        "    loss = []\n",
        "    for i in range(len(x)):\n",
        "\n",
        "      out =  qclassifier(params[0],X=x[i])+params[1]              # quantum output\n",
        "      out = np.maximum(0,np.dot(params[2],out)+params[3])         # reul on the first layer\n",
        "      loss.append(softmax(np.dot(params[4],out)+params[5]))       # softmax on the second layer\n",
        "    loss = log_loss(y,np.array(loss),labels=y_train)              # compute loss\n",
        "\n",
        "    weights = compute_sample_weight('balanced',y)\n",
        "\n",
        "    # weighted average to compensate for imbalanced batches\n",
        "    s = 0\n",
        "    for x, y in zip(loss, weights):\n",
        "      s += x * y\n",
        "\n",
        "    return s/sum(weights)\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhKU7JDHz-z_"
      },
      "source": [
        "\n",
        "# a helper function to predict the label of the image\n",
        "\n",
        "def predict(params,x,y):\n",
        "  prob = []\n",
        "  for i in range(len(x)):\n",
        "    out = qclassifier(params[0],X=x[i])+params[1]\n",
        "    out = np.maximum(0,np.dot(params[2],out)+params[3])\n",
        "    out = softmax(np.dot(params[4],out)+params[5])\n",
        "    prob.append(np.argmax(out))\n",
        "  return prob"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "wt03FA8hVPWT",
        "outputId": "2983db32-ec8b-44fe-96cd-26346cec6a7b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EaJN4-KHvp5J"
      },
      "source": [
        "### **Weights initialization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsYDfcPmxvhA",
        "outputId": "d1ceefd2-6a22-4223-fd97-01806a89f730",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "collapsed": true
      },
      "source": [
        "np.random.seed(88)\n",
        "# quantum parameters\n",
        "n_qubits= 7\n",
        "Q_n_layer = 8\n",
        "\n",
        "Qweights = qml.init.strong_ent_layers_uniform(n_layers = Q_n_layer,n_wires = n_qubits,low=0,high=1,seed=0)\n",
        "Qbias = np.random.uniform(low=-.1,high=.1,size=(n_qubits))*0\n",
        "# first layer parameters\n",
        "hidden_units = 12\n",
        "linear2_layer = np.random.randn(hidden_units,n_qubits)*0.01\n",
        "bias2_layer = np.random.randn(hidden_units)*0\n",
        "\n",
        "classes = 3\n",
        "# second layer parameters\n",
        "linear3_layer = np.random.randn(classes,hidden_units)*0.01\n",
        "bias3_layer = np.random.randn(classes)*0\n",
        "\n",
        "params = [Qweights,Qbias,linear2_layer,bias2_layer,linear3_layer,bias3_layer]\n",
        "params"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'np' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-7a89e1f2d4d9>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m88\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# quantum parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mn_qubits\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mQ_n_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nr1zKDZS1GSk"
      },
      "source": [
        "**Load the saved weights**\n",
        "\n",
        "You can download the weights from this [link](https://github.com/kareem1925/Ismailia-school-of-AI/raw/master/quantum_mnist_classification/final-grads.npy). Or, you can check the [repo](https://github.com/kareem1925/Ismailia-school-of-AI/tree/master/quantum_mnist_classification) itself."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YI_HeP8S0MFp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "collapsed": true,
        "outputId": "41945c97-d299-4cf1-f0d4-06d7bad912d9"
      },
      "source": [
        "final_weights = np.load(\"C:\\Users\\PCIS-043\\Downloads\\AIML PROJECT 4\\visa_Approval\\VISA_APPROVAL_ipynb - Colab_files\",allow_pickle=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (<ipython-input-3-18cadc635ceb>, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-18cadc635ceb>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    final_weights = np.load(\"C:\\Users\\PCIS-043\\Downloads\\AIML PROJECT 4\\visa_Approval\\VISA_APPROVAL_ipynb - Colab_files\",allow_pickle=True)\u001b[0m\n\u001b[0m                                                                                                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYcSUgwj1Nwt"
      },
      "source": [
        "Convert the one hot encoding back to its original labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHsC024gx-9T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "collapsed": true,
        "outputId": "bb7046fd-68ae-42e2-d9bd-d7130c022763"
      },
      "source": [
        "labels = la.inverse_transform(y_test)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'la' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-6211a3fa20d8>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mla\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'la' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnvcAea0yCl2"
      },
      "source": [
        "predictions=predict(final_weights,X_test,y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPmAA3dEWKE_",
        "outputId": "489da741-da4b-4200-ee4c-3c4071778043",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(accuracy_score(labels,predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ku33upXOKfNL"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(labels,predictions))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmRiCcm11ECN"
      },
      "source": [
        "### **Training procedure**\n",
        "you can run this cell and have fun with the training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CokqgN3J1AdO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "da35700c-25ab-436e-d971-0b6ffee1e44a"
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "\n",
        "learning_rate = 0.12\n",
        "epochs = 1200\n",
        "batch_size = 32\n",
        "\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "# classical adam optimizer\n",
        "loss = np.inf #random large number\n",
        "grads = []\n",
        "\n",
        "\n",
        "for it in range(epochs):\n",
        "\n",
        "    # data shuffling\n",
        "    X_train_1,y_train_1 = shuffle(X_train,y_train)\n",
        "    X_test_1,y_test_1 = shuffle(X_test,y_test)\n",
        "\n",
        "    # batching the data, i.e. every epoch processes the batch_size samples only\n",
        "    Xbatch = X_train_1[:batch_size]\n",
        "    ybatch = y_train_1[:batch_size]\n",
        "\n",
        "    params = opt.step(lambda v: cost(v, Xbatch, ybatch), params)    # updating weights\n",
        "\n",
        "\n",
        "    grads.append(params)\n",
        "\n",
        "    if it % 1 == 0:\n",
        "\n",
        "      test_loss = cost(params, X_test_1[:50], y_test_1[:50])\n",
        "      if test_loss < loss:\n",
        "        loss = test_loss\n",
        "        print('heey new loss')\n",
        "      print(\"Iter: {:5d} | test loss: {:0.7f} \".format(it + 1, test_loss))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'tf' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-0180a0f756fa>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m# classical adam optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m \u001b[0;31m#random large number\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
          ]
        }
      ]
    }
  ]
}